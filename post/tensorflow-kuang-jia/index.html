<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" >

<title>TensorFlow框架 | YvaineFire_block</title>

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://yvainefire.github.io/favicon.ico?v=1708669635041">
<link rel="stylesheet" href="https://yvainefire.github.io/styles/main.css">



<link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />
<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>



    <meta name="description" content="高效的原因

最根本的把计算图的所有计算都变成算子
算子针对硬件进行实现，以达到充分的优化。
对计算图进行了一系统的优化操作。
无依赖的算子一定程度上的并行

计算图机制
求导方法

手动求导法：手动用链式法则求解出梯度，带入公式得到数值。..." />
    <meta name="keywords" content="AICS" />
  </head>
  <body>
    <div id="app" class="main">

      <div class="sidebar" :class="{ 'full-height': menuVisible }">
  <div class="top-container" data-aos="fade-right">
    <div class="top-header-container">
      <a class="site-title-container" href="https://yvainefire.github.io">
        <img src="https://yvainefire.github.io/images/avatar.png?v=1708669635041" class="site-logo">
        <h1 class="site-title">YvaineFire_block</h1>
      </a>
      <div class="menu-btn" @click="menuVisible = !menuVisible">
        <div class="line"></div>
      </div>
    </div>
    <div>
      
        
          <a href="/" class="site-nav">
            首页
          </a>
        
      
        
          <a href="/archives" class="site-nav">
            归档
          </a>
        
      
        
          <a href="/tags" class="site-nav">
            标签
          </a>
        
      
        
          <a href="/post/about" class="site-nav">
            关于
          </a>
        
      
    </div>
  </div>
  <div class="bottom-container" data-aos="flip-up" data-aos-offset="0">
    <div class="social-container">
      
        
      
        
      
        
      
        
      
        
      
    </div>
    <div class="site-description">
      Rush Rush B
    </div>
    <div class="site-footer">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | <a class="rss" href="https://yvainefire.github.io/atom.xml" target="_blank">RSS</a>
    </div>
  </div>
</div>


      <div class="main-container">
        <div class="content-container" data-aos="fade-up">
          <div class="post-detail">
            <h2 class="post-title">TensorFlow框架</h2>
            <div class="post-date">2022-07-31</div>
            
            <div class="post-content" v-pre>
              <h2 id="高效的原因">高效的原因</h2>
<ul>
<li>最根本的把计算图的所有计算都变成算子</li>
<li>算子针对硬件进行实现，以达到充分的优化。</li>
<li>对计算图进行了一系统的优化操作。</li>
<li>无依赖的算子一定程度上的并行</li>
</ul>
<h2 id="计算图机制">计算图机制</h2>
<h3 id="求导方法">求导方法</h3>
<ul>
<li>手动求导法：手动用链式法则求解出梯度，带入公式得到数值。但是对于大规模的网络求解复杂，同时可移植性不强。</li>
<li>数值求导法：利用倒数的原始定义（极限），去一很小的值。但是计算量大，误差也大。</li>
<li>符号求导法：利用求导规则对表达式进行自动操作。但是可以会出现表达式膨胀。也就是如果表达式过于复杂，采用求导规则推出的公式可能会很大，比如对于一个由递推构造的公式，就可能出现这种情况。</li>
<li>自动求导法：结合了数值求导法和符号求导法。在求导的过程中利用后一层求导的结果（每次先求出后一层的结果，再反向传递）以减少公式膨胀，再利用符号求导公式求出本层的未知数，相对后一层的偏导数（每一层只需要求出其相对后一层的偏导数），需要保留每一层的导数和每一层前向传播的结果。实际上是链式法则求导公式的变形（求导的合并）。</li>
</ul>
<h3 id="检查点机制">检查点机制</h3>
<p>模型的训练过程中出现意外情况导致训练终止，所有在训练过程中需要模型的保持和恢复。</p>
<p>使用tf.train.Saver()来存储参数到checkpoint文件中</p>
<p>使用saver.restore()来恢复变量，不需要再进行变量的初始化</p>
<p>通过在计算图中插入Save节点和Restore及其关联节点来完成。</p>
<h3 id="控制流">控制流？</h3>
<p>使用控制流算子来让数据流能在不同复杂控制流场景应用</p>
<p>引入少量简单基础操作，提供丰富的控制流表达</p>
<p>每个一操作都是在执行帧中被执行，控制流负责创建和管理这些执行帧。</p>
<ul>
<li>Switch：一个张量输入，一个控制输入，两个输出。根据控制输入选择张量输出的方向。</li>
<li>Merge：两个张量输入，一个张量输出。将其中任意一个准备好的输入输出。</li>
<li>Enter：一个张量输入，一个张量输出。将它的输入推向名为name的执行帧。</li>
<li>Exit：一个张量输入，一个张量输出，将一个张量从他的子执行帧推向它的父执行帧。</li>
<li>NextIteration:</li>
</ul>
<p>构建条件语句</p>
<p>构建循环语句</p>
<h3 id="计算图执行模式">计算图执行模式</h3>
<p>client：用户通过编程使用session接口与master和worker通信。提交给master需要计算的任务。</p>
<p>master：控制所有的worker按照计算图执行。</p>
<p>worker：每一个worker负责一个或多个计算图的仲裁和访问，并根据master的指令执行这些计算设备的计算图节点。</p>
<p>设备：CPU或者GPU</p>
<ul>
<li>单master单worker单GPU（本地单设备执行）：计算图按照结点间的关系按顺序执行，每个节点有一个计数器记录其还未执行的依赖节点的个数。计数器为0时才将该节点添加到就绪队列中。</li>
<li>单master单worker多GPU（本地多设备执行）：CPU作为参数的服务器，用于保存参数和变量、计算梯度平均等。GPU作为worker，用作模型训练。数据分割为batch，将batch分配给不同的GPU，用于模型的前向计算和反向计算，计算出个batch的loss和梯度，再将梯度交由CPU进行平均。CPU和GPU分别进行参数的更新。</li>
<li>单master多worker多GPU（分布式执行）：client，master和worker可以工作于不同的机器上。</li>
</ul>
<h3 id="计算图本地执行">计算图本地执行</h3>
<ul>
<li>计算图剪枝：得到本地运行的最小子图。为输入输出建立与外界的联系（增加一个额外的source结点作为所有输入节点的起点，添加一个额外的sink节点作为所有输出节点的终止节点）。除去与最终输出节点无关联的节点和边（广度搜索，删除与最终输出节点无关联的节点和边，并将新生成的连通图中入度为0的节点连接到source节点，出度为0的节点连接到sink节点 ***这样连接怎么能还原原来的拓扑关系？***）。</li>
<li>计算图分配：使用cost model根据输入输出tensor的数量和预计运行时间来考虑设备之间的分配以达到最快时间进行计算的目的。</li>
<li>计算图优化：图优化由Grappler模块来实现。根据硬件结构调整调度策略，加快计算速度同时减少推断过程中所用的峰值内存。包括常量折叠（类似编译过程中将一部分常量或可以提前计算的量先计算出来作为新的节点直接使用），算术简化（公共表达式消除，提取公因式，算术化简），布局优化（TensorFLow采用NHWC，GPU采用NCHW，减少数据格式间的转换次数），重映射（算子融合，将高频率使用的子图用单独的算子来替换，可以减少不同计算节点间的调度的开销即主要是访存的开销同时方便底层硬件的处理）</li>
<li>计算图切分：完成每个节点的分配后，将整个计算图按照所分配的设备分成若干的子图，每个设备对于一张子图。对于有依赖关系但是被分配到不同设备的节点，通过在设备边界插入send或者recv节点来进行通信。</li>
</ul>
<h2 id="系统实现">系统实现</h2>
<h3 id="整体框架">整体框架</h3>
<p>C/C++为基础再封装为python，go，java......</p>
<h3 id="计算图执行模块">计算图执行模块</h3>
<p>Session：用户与运行时的接口，session接收数据</p>
<p>每个设定有一个执行器，负责本设备上算计图的执行。</p>
<p>Run函数是Session执行的核心逻辑，完成计算图的执行，包括传参、运行和返回。</p>
<p>Run函数：传参，创建或得到执行器，执行器绑带在设备上，调用函数调用帧函数处理执行器的输入和输出，执行器中feed中获取输入并将输出写入</p>
<p>RunInternal：开始并执行执行器，如果是多设备并行执行，则需要ExecutorBarrier协调多个Executor来并行计算。</p>
<p>执行流：一个能够存储计算任务的队列。在进行计算图优化，计算图切分之后将形成的每个最小子图作为流分配给一个个执行器。流间的任务可以并行执行，流内的任务只能串行执行。流越少，同步各流的开销就越小，流越多，并行的可能性越大。</p>
<p>执行器的核心ScheduleReady：维护两个队列。ready队列（预执行队列），inline_ready队列（当前线程要处理的队列）。如果inline_ready为空，则使用线程去处理ready队列中的每个节点。如果inline_ready不为空，且ready队列的处理未完成，如果节点为低开销的则放到inline_ready队列中执行。否则启动新线程。如果inline_ready为空，且ready队列处理完了，且当前节点为高开销的，则将高开销节点放入inline_ready中否则启动新线程的执行。</p>
<h3 id="设备抽象和管理">设备抽象和管理</h3>
<p>设备分为本地设备和远程设备，</p>
<p>使用注册机制来管理设备，可以通过注册口支持自定义的设备。</p>
<h3 id="网络和通信">网络和通信</h3>
<p>使用Rendezvous机制来完成数据的交互</p>
<p>Rendezvous机制向外提供了Send和Receive，使用这两个节点来进行设备间的通信。</p>
<p>Rendezvous机制使用了类似生产者消费者的模型。每个Rendezvous实例拥有一个通道表，记录了每对Send和Receive的关系和状态。</p>
<h3 id="算子实现">算子实现</h3>
<p>OpKernel将算子绑定到底层硬件</p>
<p>通过注册机制来支持不同的算子和相应的OpKernel</p>
<p>OpKernel可以是同步(Compute()返回即认为数据已经处理完了)的也可以是异步的</p>
<p>C++ 中Session Run流程</p>
<ul>
<li>创建执行器：创建graph进行优化，分割为一些子图。子图分配给一系列执行器，执行器进行初始化，创建控制流信息和kernel。</li>
<li>创建函数调用帧：配置执行相关的feed和fetch参数。即输入和输出。</li>
<li>执行器并行执行：执行器为每个Op分配上下文信息。将每个入度为0的节点，分配到Ready队列。ScheduleReady函数将这些节点交给run执行。</li>
</ul>

            </div>
            
              <div class="tag-container">
                
                  <a href="https://yvainefire.github.io/tag/MnAQ9uAR_/" class="tag">
                    AICS
                  </a>
                
              </div>
            
            
              <div class="next-post">
                <div class="next">下一篇</div>
                <a href="https://yvainefire.github.io/post/cnn/">
                  <h3 class="post-title">
                    CNN
                  </h3>
                </a>
              </div>
            

            

          </div>

        </div>
      </div>
    </div>

    <script src="https://unpkg.com/aos@next/dist/aos.js"></script>
<script type="application/javascript">

AOS.init();

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>






  </body>
</html>
